# pages/8_üí¨_Tr√≤_chuy·ªán.py
import asyncio
import base64
import html
import os
import random
import re
import time
from datetime import datetime
from io import BytesIO

import pandas as pd
import streamlit as st

# Optional: Gemini - B·ªä V√î HI·ªÜU H√ìA ƒê·ªÇ TR√ÅNH L·ªñI K·∫æT N·ªêI
# T√¥i gi·ªØ l·∫°i code nh∆∞ng s·∫Ω kh√¥ng c·ªë g·∫Øng k·∫øt n·ªëi ban ƒë·∫ßu
GENAI_AVAILABLE = False
# try:
#     import google.generativeai as genai
#     GENAI_AVAILABLE = True
# except ImportError:
#     GENAI_AVAILABLE = False

# Fallback TTS
try:
    from gtts import gTTS
    GTTS_AVAILABLE = True
except ImportError:
    GTTS_AVAILABLE = False

# Preferred neural TTS (Microsoft Edge TTS)
try:
    import edge_tts
    EDGE_TTS_AVAILABLE = True
except ImportError:
    EDGE_TTS_AVAILABLE = False


# ========== 0) H·∫∞NG S·ªê V√Ä TR·∫†NG TH√ÅI ==========

STATE_CHAT = "chat"
STATE_JOURNAL = "journal"
STATE_RELAX = "relax"

CHAT_STATE_MAIN = "main"
CHAT_STATE_TAM_SU_SELECTION = "tam_su_selection"
CHAT_STATE_TAM_SU_CHAT = "tam_su_chat"
CHAT_STATE_GIAO_TIEP_SELECTION_BASIC = "giao_tiep_selection_basic"
CHAT_STATE_GIAO_TIEP_SELECTION_EXTENDED = "giao_tiep_selection_extended"
CHAT_STATE_GIAO_TIEP_PRACTICE = "giao_tiep_practice"
CHAT_STATE_AWAITING_FOLLOWUP = "awaiting_followup"

# ========== 1) C·∫§U H√åNH UI & CSS ==========

st.set_page_config(page_title="üí¨ Tr√≤ chuy·ªán", page_icon="üí¨", layout="wide")

st.markdown(
    """
<style>
/* Reset chrome */
#MainMenu, footer, header { visibility: hidden; }

/* Layout */
.stApp { background-color: #FFFFFF; }
.chat-shell { 
    max-width: 820px; 
    margin: 0 auto; 
    padding-top: 64px; 
    padding-bottom: 150px; /* Increased to avoid overlap with input bar */
}

/* Header sticky gi·ªëng app shopping */
.chat-header {
  position: fixed; top: 0; left: 0; right: 0; z-index: 999;
  background: #fff; border-bottom: 1px solid #efefef;
  box-shadow: 0 2px 10px rgba(0,0,0,0.05);
}
.chat-header-inner {
  max-width: 820px; margin: 0 auto; padding: 12px 16px;
  display: flex; align-items: center; gap: 12px;
}
.chat-title { font-weight: 700; font-size: 1.05rem; }

/* Bubbles */
.bubble-row { display:flex; margin: 12px 0; }
.bubble-user { justify-content: flex-end; }
.msg {
  border-radius: 18px; padding: 12px 16px; max-width: 75%;
  font-size: 1rem; line-height: 1.5; word-wrap: break-word;
}
.msg-user { 
  background: linear-gradient(135deg, #25D366, #128C7E); 
  color: white; 
  border-top-right-radius: 6px; 
  box-shadow: 0 1px 2px rgba(0,0,0,0.1);
}
.msg-bot { 
  background: #F3F4F6; color: #111; border-top-left-radius: 6px;
  box-shadow: 0 1px 2px rgba(0,0,0,0.05);
}

/* Typing indicator */
.typing { display:inline-block; padding: 8px 14px; border-radius: 18px; background: #F3F4F6; }
.typing span {
  height: 8px; width: 8px; margin: 0 2px; background-color: #9E9E9E;
  display: inline-block; border-radius: 50%; opacity: 0.5; animation: bob 1s infinite;
}
@keyframes bob { 0%,100%{transform:translateY(0)} 50%{transform:translateY(-6px)} }
.typing span:nth-child(1){animation-delay:-0.3s} .typing span:nth-child(2){animation-delay:-0.15s}

/* Quick actions (chips) */
.quick-actions { display:flex; gap:10px; flex-wrap: wrap; margin: 10px 0 16px; }
.chip {
  border: none; color: white; background: linear-gradient(135deg, #0084FF, #0069cc);
  border-radius: 20px; padding: 8px 14px; font-size: 0.9rem; cursor: pointer;
  transition: all 0.2s ease;
  box-shadow: 0 1px 3px rgba(0,0,0,0.1);
}
.chip:hover { transform: translateY(-2px); box-shadow: 0 3px 6px rgba(0,0,0,0.15); }

/* Sticky input */
.input-bar {
  position: fixed; left: 0; right: 0; bottom: 0; z-index: 999;
  background: #fff; border-top: 1px solid #efefef;
  box-shadow: 0 -2px 10px rgba(0,0,0,0.05);
}
.input-inner {
  max-width: 820px; margin: 0 auto; padding: 15px 16px;
}

/* Buttons */
button {
  transition: all 0.2s ease;
}
button:hover {
  transform: translateY(-2px);
  box-shadow: 0 3px 6px rgba(0,0,0,0.1);
}

/* Option pills */
.option-pill {
  background: #f0f2f5;
  border-radius: 18px;
  padding: 10px 14px;
  margin: 5px 0;
  cursor: pointer;
  transition: all 0.2s;
  border: 1px solid #e4e6eb;
}

.option-pill:hover {
  background: #e4e6eb;
}

/* Scrollbar customization */
::-webkit-scrollbar {
  width: 8px;
}
::-webkit-scrollbar-track {
  background: #f1f1f1;
}
::-webkit-scrollbar-thumb {
  background: #c1c1c1;
  border-radius: 10px;
}
::-webkit-scrollbar-thumb:hover {
  background: #a8a8a8;
}

</style>
""",
    unsafe_allow_html=True,
)

# Header
st.markdown(
    """
<div class="chat-header">
  <div class="chat-header-inner">
    <div>üí¨</div>
    <div class="chat-title">Tr√≤ chuy·ªán - B·∫°n ƒê·ªìng H√†nh</div>
  </div>
</div>
""",
    unsafe_allow_html=True,
)


# ========== 2) CONFIG D·ªÆ LI·ªÜU N·ªòI DUNG ==========

@st.cache_data
def get_config():
    return {
        "ui": {
            "title": "B·∫°n ƒë·ªìng h√†nh üíñ",
            "input_placeholder": "Nh·∫≠p tin nh·∫Øn c·ªßa b·∫°n...",
        },
        "tam_su": {
            "intro_message": "H√¥m nay b·∫°n c·∫£m th·∫•y nh∆∞ th·∫ø n√†o n√®? M√¨nh lu√¥n s·∫µn l√≤ng l·∫Øng nghe b·∫°n nha üåü",
            "positive_affirmation_trigger": "üåº Nghe m·ªôt l·ªùi t√≠ch c·ª±c",
            "positive_affirmations": [
                "B·∫°n m·∫°nh m·∫Ω h∆°n b·∫°n nghƒ© r·∫•t nhi·ªÅu.",
                "M·ªói b∆∞·ªõc nh·ªè b·∫°n ƒëi ƒë·ªÅu l√† m·ªôt th√†nh c√¥ng l·ªõn.",
                "C·∫£m x√∫c c·ªßa b·∫°n l√† th·∫≠t v√† ƒë√°ng ƒë∆∞·ª£c t√¥n tr·ªçng.",
                "B·∫°n x·ª©ng ƒë√°ng ƒë∆∞·ª£c y√™u th∆∞∆°ng v√† h·∫°nh ph√∫c.",
                "H√¥m nay c√≥ th·ªÉ kh√≥ khƒÉn, nh∆∞ng ng√†y mai s·∫Ω t·ªët h∆°n."
            ],
            "moods": {
                "üòÑ Vui": {
                    "keywords": ["vui", "h·∫°nh ph√∫c", "tuy·ªát v·ªùi", "gi·ªèi", "ƒëi ch∆°i", "üéâ", "üòÑ"],
                    "initial": "Tuy·ªát v·ªùi qu√°! C√≥ chuy·ªán g√¨ vui kh√¥ng, k·ªÉ m√¨nh nghe v·ªõi n√®!",
                    "styles": {
                        "Khuy·∫øn kh√≠ch": [
                            "Nghe l√† th·∫•y vui gi√πm b·∫°n lu√¥n √°! K·ªÉ th√™m ch√∫t n·ªØa ƒëi!",
                            "H√¥m nay ch·∫Øc l√† m·ªôt ng√†y ƒë·∫∑c bi·ªát r·ªìi! Chia s·∫ª th√™m nh√©!"
                        ]
                    }
                },
                "üòî Bu·ªìn": {
                    "keywords": ["bu·ªìn", "ch√°n", "stress", "c√¥ ƒë∆°n", "t·ªá", "üòî"],
                    "initial": "√îi, m√¨nh nghe r·ªìi n√®. C√≥ chuy·ªán g√¨ l√†m b·∫°n bu·ªìn v·∫≠y?",
                    "styles": {
                        "L·∫Øng nghe": [
                            "Kh√¥ng sao ƒë√¢u, b·∫°n bu·ªìn c≈©ng ƒë∆∞·ª£c m√†. K·ªÉ m√¨nh nghe th√™m nh√©.",
                            "B·∫°n kh√¥ng c·∫ßn ph·∫£i g·ªìng ƒë√¢u, m√¨nh ·ªü ƒë√¢y n√®."
                        ]
                    }
                }
            }
        },
        "giao_tiep": {
            "intro_message": "H√£y ch·ªçn m·ªôt t√¨nh hu·ªëng b√™n d∆∞·ªõi ƒë·ªÉ m√¨nh c√πng luy·ªán t·∫≠p nh√©!",
            "confirm_buttons": {"understood": "‚úÖ ƒê√£ hi·ªÉu!", "not_understood": "‚ùì Ch∆∞a r√µ l·∫Øm!"},
            "scenarios_basic": {
                "üëã Ch√†o h·ªèi b·∫°n b√®": "B·∫°n c√≥ th·ªÉ n√≥i: \"Ch√†o b·∫°n, h√¥m nay vui kh√¥ng?\"",
                "üôã H·ªèi b√†i th·∫ßy c√¥": "B·∫°n th·ª≠ h·ªèi: \"Th·∫ßy/c√¥ ∆°i, ph·∫ßn n√†y em ch∆∞a r√µ ·∫°?\""
            },
            "scenarios_extended": {
                "üìö Nh·ªù b·∫°n gi√∫p ƒë·ª°": "B·∫°n th·ª≠ n√≥i: \"C·∫≠u ch·ªâ m√¨nh ch·ªó n√†y v·ªõi ƒë∆∞·ª£c kh√¥ng?\"",
                "üôè Xin l·ªói khi ƒë·∫øn mu·ªôn": "B·∫°n c√≥ th·ªÉ n√≥i: \"Em xin l·ªói v√¨ ƒë√£ ƒë·∫øn mu·ªôn, em c√≥ th·ªÉ v√†o l·ªõp kh√¥ng ·∫°?\"",
                "ü§î H·ªèi khi kh√¥ng hi·ªÉu b√†i": "Th·ª≠ n√≥i: \"Em ch∆∞a hi·ªÉu ph·∫ßn n√†y, th·∫ßy/c√¥ c√≥ th·ªÉ gi·∫£i th√≠ch l·∫°i ƒë∆∞·ª£c kh√¥ng ·∫°?\"",
            },
        },
        "general": {
            "neutral_replies": [
                "M√¨nh ch∆∞a r√µ l·∫Øm, b·∫°n n√≥i c·ª• th·ªÉ h∆°n ƒë∆∞·ª£c kh√¥ng?",
                "M√¨nh ƒëang nghe b·∫°n n√®, b·∫°n mu·ªën n√≥i th√™m ƒëi·ªÅu g√¨ kh√¥ng?",
                "B·∫°n c√≥ th·ªÉ chia s·∫ª th√™m v·ªÅ ƒëi·ªÅu ƒë√≥ kh√¥ng?",
                "M√¨nh mu·ªën hi·ªÉu b·∫°n h∆°n. B·∫°n c√≥ th·ªÉ k·ªÉ chi ti·∫øt h∆°n ƒë∆∞·ª£c kh√¥ng?"
            ],
            "follow_up_prompt": "B·∫°n mu·ªën ti·∫øp t·ª•c t√¢m s·ª± hay luy·ªán n√≥i chuy·ªán trong l·ªõp n√®?",
            "end_chat_replies": [
                "C·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª v·ªõi m√¨nh h√¥m nay nha. M√¨nh lu√¥n s·∫µn s√†ng khi b·∫°n c·∫ßn üíñ",
                "B·∫°n ƒë√£ l√†m r·∫•t t·ªët khi b·ªôc l·ªô c·∫£m x√∫c. Khi n√†o c·∫ßn, m√¨nh v·∫´n ·ªü ƒë√¢y ‚ú®"
            ],
            "simulated_ai_responses": [
                "M√¨nh hi·ªÉu r·ªìi. C·∫£m ∆°n b·∫°n ƒë√£ chia s·∫ª. ƒê√¥i khi m·ªçi chuy·ªán c√≥ v·∫ª kh√≥ khƒÉn, nh∆∞ng b·∫°n r·∫•t m·∫°nh m·∫Ω!",
                "C√¢u chuy·ªán c·ªßa b·∫°n r·∫•t ƒë√°ng suy nghƒ©. M√¨nh lu√¥n ·ªü ƒë√¢y ƒë·ªÉ l·∫Øng nghe th√™m n·∫øu b·∫°n mu·ªën t√¢m s·ª±.",
                "M√¨nh c·∫£m nh·∫≠n ƒë∆∞·ª£c nh·ªØng g√¨ b·∫°n ƒëang tr·∫£i qua. B·∫°n c√≥ th·ªÉ n√≥i th√™m v·ªÅ c·∫£m x√∫c ƒë√≥ kh√¥ng?",
                "ƒê√≥ l√† m·ªôt c√¢u h·ªèi hay. M√¨nh tin r·∫±ng b·∫°n s·∫Ω t√¨m ra c√°ch gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y. M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n suy nghƒ© th√™m.",
            ]
        },
    }

CONFIG = get_config()

# Gemini optional - V√¥ hi·ªáu h√≥a ƒë·ªÉ tr√°nh l·ªói k·∫øt n·ªëi
AI_ENABLED = False
if GENAI_AVAILABLE:
    try:
        api_key = None
        try:
            api_key = st.secrets.get("GOOGLE_API_KEY")
        except:
            pass
            
        if not api_key:
            api_key = os.environ.get("GOOGLE_API_KEY")
            
        if api_key:
            import google.generativeai as genai # Import ·ªü ƒë√¢y n·∫øu c·∫ßn
            genai.configure(api_key=api_key)
            # D√πng 'gemini-2.5-flash' ho·∫∑c 'gemini-1.5-flash'
            gemini_model = genai.GenerativeModel("gemini-1.5-flash")
            AI_ENABLED = True
        else:
            st.sidebar.warning("Ch∆∞a c·∫•u h√¨nh API key cho Gemini. ƒê√£ chuy·ªÉn sang ch·∫ø ƒë·ªô d·ª± ph√≤ng.", icon="‚ö†Ô∏è")
    except Exception as e:
        st.sidebar.error(f"L·ªói c·∫•u h√¨nh Gemini: {str(e)[:50]}... ƒê√£ chuy·ªÉn sang ch·∫ø ƒë·ªô d·ª± ph√≤ng.", icon="üö®")


# ========== 3) SESSION STATE ==========

# Initialize session state
if "page_state" not in st.session_state:
    st.session_state.page_state = STATE_CHAT
    
if "chat_state" not in st.session_state:
    st.session_state.chat_state = CHAT_STATE_MAIN
    
if "history" not in st.session_state:
    st.session_state.history = [
        {"sender": "bot", "text": "Ch√†o b·∫°n, m√¨nh l√† B·∫°n ƒë·ªìng h√†nh ƒë√¢y! M√¨nh c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n h√¥m nay?"}
    ]
    
if "turns" not in st.session_state:
    st.session_state.turns = 0
    
if "current_mood" not in st.session_state:
    st.session_state.current_mood = None
    
if "current_scenario" not in st.session_state:
    st.session_state.current_scenario = None
    
# ƒê√£ x√≥a 'user_input_buffer' v√¨ kh√¥ng s·ª≠ d·ª•ng
    
if "is_processing" not in st.session_state:
    st.session_state.is_processing = False

# Voice settings defaults
if "tts_enabled" not in st.session_state:
    st.session_state.tts_enabled = True
    
if "tts_voice" not in st.session_state:
    st.session_state.tts_voice = "vi-VN-HoaiMyNeural"  # n·ªØ
    
if "tts_rate" not in st.session_state:
    st.session_state.tts_rate = 0  # %

# Nh·∫≠t k√Ω (S·ª≠ d·ª•ng session state thay v√¨ file c·ª•c b·ªô)
if "journal_data" not in st.session_state:
    st.session_state.journal_data = pd.DataFrame(columns=["Ng√†y", "C·∫£m x√∫c", "Ghi ch√∫"])


# ========== 4) TTS (EDGE TTS NEURAL + FALLBACK GTTS) ==========

# @st.cache_data removed from gtts_bytes/edge_tts_bytes to ensure fresh run if args change slightly (optional but safer)
# Tuy nhi√™n, trong context n√†y, t√¥i gi·ªØ l·∫°i @st.cache_data ƒë·ªÉ t·ªëi ∆∞u h√≥a performance nh∆∞ trong code g·ªëc.

@st.cache_data(show_spinner=False)
def gtts_bytes(text):
    """Generate audio using gTTS as fallback"""
    if not GTTS_AVAILABLE:
        return None
    try:
        bio = BytesIO()
        tts = gTTS(text=text, lang="vi")
        tts.write_to_fp(bio)
        bio.seek(0)
        return bio.read()
    except Exception as e:
        print(f"L·ªói gTTS: {e}")
        return None

@st.cache_data(show_spinner=False)
def edge_tts_bytes(text, voice, rate_pct):
    """Generate audio using Edge TTS (preferred method)"""
    if not EDGE_TTS_AVAILABLE:
        return None
    
    try:
        # S·ª≠ d·ª•ng threading.Thread ho·∫∑c multiprocessing ƒë·ªÉ tr√°nh block lu·ªìng ch√≠nh
        # Tuy nhi√™n, ƒë·ªÉ ƒë∆°n gi·∫£n v√† ph√π h·ª£p v·ªõi Streamlit, ch√∫ng ta d√πng asyncio trong h√†m cache
        # v√† gi·∫£ ƒë·ªãnh m√¥i tr∆∞·ªùng cho ph√©p ch·∫°y asyncio.
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        async def _synthesize():
            # ƒê·∫£m b·∫£o rate_pct l√† s·ªë nguy√™n
            rate_pct_int = int(rate_pct)
            rate_str = f"{'+' if rate_pct_int>=0 else ''}{rate_pct_int}%"
            communicate = edge_tts.Communicate(text, voice=voice, rate=rate_str)
            audio = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio += chunk["data"]
            return audio
            
        audio_data = loop.run_until_complete(_synthesize())
        loop.close()
        return audio_data
        
    except Exception as e:
        print(f"L·ªói Edge TTS: {e}")
        return None

def synthesize_tts(text, voice, rate_pct):
    """Generate text-to-speech audio using available methods"""
    # Prefer Edge TTS neural
    if EDGE_TTS_AVAILABLE:
        audio = edge_tts_bytes(text, voice, rate_pct)
        if audio:
            return audio
            
    # Fallback gTTS
    return gtts_bytes(text)

def autoplay_audio(audio_data):
    """Play audio data automatically in the streamlit app"""
    if audio_data is None:
        return
        
    try:
        b64 = base64.b64encode(audio_data).decode()
        md = f"""
        <audio autoplay="true">
          <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        </audio>
        """
        st.components.v1.html(md, height=0)
    except Exception as e:
        print(f"L·ªói ph√°t √¢m thanh: {e}")


# ========== 5) LOGIC CHAT & AI ==========

def add_message(sender, text):
    """Add a message to the chat history"""
    st.session_state.history.append({"sender": sender, "text": text})

def detect_mood_from_text(text):
    """Detect mood from user input text"""
    cfg = CONFIG["tam_su"]["moods"]
    lowered = text.lower()
    # T√¨m t·ª´ kh√≥a
    tokens = set(re.findall(r"\b\w+\b", lowered))
    # T√¨m emoji
    emojis = set(re.findall(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]+', text))
    # G·ªôp c·∫£ t·ª´ kh√≥a v√† emoji (ch·ªâ l·∫•y c√°c emoji c√≥ trong c·∫•u h√¨nh)
    all_tokens = tokens.union(ch for mood_cfg in cfg.values() for ch in mood_cfg["keywords"] if ch in text)
    
    best, score = None, 0
    for mood, m_cfg in cfg.items():
        kws = set(m_cfg["keywords"])
        # Ch·ªâ x√©t t·ª´ kh√≥a ho·∫∑c emoji c√≥ trong c·∫•u h√¨nh
        matches = len(all_tokens.intersection(kws))
        if matches > score:
            best, score = mood, matches
    return best

def get_ai_response(prompt):
    """
    Call Gemini AI for text generation ho·∫∑c d√πng Fallback Logic.
    Ph·∫ßn n√†y s·∫Ω b·ªã block n·∫øu AI_ENABLED = True.
    """
    if AI_ENABLED:
        try:
            contextual = (
                "H√£y tr·∫£ l·ªùi nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh AI th√¢n thi·ªán, ki√™n nh·∫´n v√† th·∫•u hi·ªÉu d√†nh cho h·ªçc sinh."
                " Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn (d∆∞·ªõi 100 t·ª´) v√† gi√†u ƒë·ªìng c·∫£m. "
                " H·∫°n ch·∫ø tr·∫£ l·ªùi gi√°o ƒëi·ªÅu v√† s·ª≠ d·ª•ng ng√¥n ng·ªØ t·ª± nhi√™n, th√¢n thi·ªán.\n\n"
                f"C√¢u h·ªèi/Chia s·∫ª c·ªßa ng∆∞·ªùi d√πng: '{prompt}'"
            )
            # D√πng st.spinner ·ªü giao di·ªán ƒë·ªÉ hi·ªÉn th·ªã tr·∫°ng th√°i ch·ªù
            # L∆ØU √ù: H√†m n√†y BLOCK lu·ªìng, n√™n c·∫ßn x·ª≠ l√Ω hi·ªÉn th·ªã hi·ªáu ·ª©ng "ƒêang g√µ" ·ªü ph√≠a g·ªçi.
            resp = gemini_model.generate_content(contextual)
            return resp.text or random.choice(CONFIG["general"]["neutral_replies"])
        except Exception as e:
            # N·∫øu c√≥ l·ªói khi g·ªçi AI (v√≠ d·ª•: timeout, API key h·∫øt h·∫°n)
            return f"Xin l·ªói, c√≥ l·ªói khi k·∫øt n·ªëi AI: {str(e)[:50]}.... ƒê√£ chuy·ªÉn sang ph·∫£n h·ªìi d·ª± ph√≤ng: {random.choice(CONFIG['general']['simulated_ai_responses'])}"
            
    # Fallback Logic (D·ª± ph√≤ng)
    # M√¥ ph·ªèng th·ªùi gian ch·ªù ƒë·ªÉ ng∆∞·ªùi d√πng c·∫£m nh·∫≠n ·ª©ng d·ª•ng ƒëang "nghƒ©"
    time.sleep(random.uniform(1.0, 2.5)) 
    return random.choice(CONFIG["general"]["simulated_ai_responses"])


def respond_bot(text):
    """Generate bot response with optional text-to-speech"""
    # Kh√¥ng c·∫ßn d√πng st.spinner trong h√†m n√†y n·ªØa, d√πng b√™n ngo√†i khi g·ªçi h√†m AI
    add_message("bot", text)
    
    # Synthesize voice if enabled
    if st.session_state.tts_enabled:
        audio = synthesize_tts(text, st.session_state.tts_voice, st.session_state.tts_rate)
        if audio:
            autoplay_audio(audio)
            

# ========== 6) GIAO DI·ªÜN CH√çNH (SHOPPING CHAT STYLE) ==========

with st.sidebar:
    st.markdown("### C√†i ƒë·∫∑t gi·ªçng n√≥i")
    st.session_state.tts_enabled = st.toggle("ƒê·ªçc to ph·∫£n h·ªìi", value=st.session_state.tts_enabled)
    
    voice = st.selectbox(
        "Gi·ªçng ƒë·ªçc",
        options=[
            "vi-VN-HoaiMyNeural (N·ªØ)",
            "vi-VN-NamMinhNeural (Nam)"
        ],
        index=0 if st.session_state.tts_voice.endswith("HoaiMyNeural") else 1
    )
    st.session_state.tts_voice = "vi-VN-HoaiMyNeural" if "HoaiMy" in voice else "vi-VN-NamMinhNeural"
    
    rate = st.slider("T·ªëc ƒë·ªô n√≥i (%)", -50, 50, st.session_state.tts_rate, step=5)
    st.session_state.tts_rate = rate
    
    st.divider()
    
    # About section
    st.markdown("### Gi·ªõi thi·ªáu")
    if not AI_ENABLED:
         st.warning("‚ö†Ô∏è **Ch·∫ø ƒë·ªô D·ª± ph√≤ng:** Ch·ª©c nƒÉng AI b·ªã v√¥ hi·ªáu h√≥a do l·ªói k·∫øt n·ªëi/c·∫•u h√¨nh API. Ph·∫£n h·ªìi chung ƒë∆∞·ª£c m√¥ ph·ªèng.", icon="üö´")
    st.markdown("""
    **B·∫°n ƒê·ªìng H√†nh** l√† chatbot h·ªó tr·ª£ t√¢m l√Ω v√† k·ªπ nƒÉng giao ti·∫øp cho h·ªçc sinh.
    
    Chatbot c√≥ th·ªÉ:
    - L·∫Øng nghe v√† ƒë·ªìng c·∫£m v·ªõi c·∫£m x√∫c
    - H·ªó tr·ª£ luy·ªán t·∫≠p giao ti·∫øp
    - Ghi nh·∫≠t k√Ω c·∫£m x√∫c
    - H∆∞·ªõng d·∫´n b√†i t·∫≠p th∆∞ gi√£n
    """)
    
    st.markdown("Phi√™n b·∫£n: 1.2.1 (S·ª≠a l·ªói)")

# Shell for chat
st.markdown('<div class="chat-shell">', unsafe_allow_html=True)

# Quick action chips
quick_actions_col = st.container()
with quick_actions_col:
    # Logic ch·ªâ hi·ªÉn th·ªã quick actions khi ·ªü tr·∫°ng th√°i MAIN ho·∫∑c AWAITING_FOLLOWUP
    if st.session_state.chat_state in (CHAT_STATE_MAIN, CHAT_STATE_AWAITING_FOLLOWUP):
        st.markdown('<div class="quick-actions">', unsafe_allow_html=True)
        qa_cols = st.columns(4)
        with qa_cols[0]:
            if st.button("üíñ T√¢m s·ª±", use_container_width=True, key="btn_tam_su"):
                st.session_state.chat_state = CHAT_STATE_TAM_SU_SELECTION
                respond_bot(CONFIG["tam_su"]["intro_message"])
                st.rerun()
        with qa_cols[1]:
            if st.button("üó£Ô∏è Luy·ªán giao ti·∫øp", use_container_width=True, key="btn_giao_tiep"):
                st.session_state.chat_state = CHAT_STATE_GIAO_TIEP_SELECTION_BASIC
                respond_bot(CONFIG["giao_tiep"]["intro_message"])
                st.rerun()
        with qa_cols[2]:
            if st.button("üìì Nh·∫≠t k√Ω", use_container_width=True, key="btn_journal"):
                st.session_state.page_state = STATE_JOURNAL
                st.rerun()
        with qa_cols[3]:
            if st.button("üòå Th∆∞ gi√£n", use_container_width=True, key="btn_relax"):
                st.session_state.page_state = STATE_RELAX
                st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)

# Message history
message_container = st.container()
with message_container:
    for m in st.session_state.history:
        cls_row = "bubble-row bubble-user" if m["sender"] == "user" else "bubble-row"
        cls_msg = "msg msg-user" if m["sender"] == "user" else "msg msg-bot"
        st.markdown(
            f'<div class="{cls_row}"><div class="{cls_msg}">{html.escape(m["text"])}</div></div>',
            unsafe_allow_html=True
        )

    # Hi·ªÉn th·ªã Typing Indicator T·∫†M TH·ªúI (ƒë·ªÉ gi·ªØ v·ªã tr√≠)
    # L∆ØU √ù: Hi·ªáu ·ª©ng n√†y ch·ªâ th·ª±c s·ª± ho·∫°t ƒë·ªông n·∫øu c√≥ 2 l·∫ßn rerun, r·∫•t kh√≥ trong Streamlit
    # T√¥i s·∫Ω c·ªë g·∫Øng gi·ªØ nguy√™n logic ƒë·ªÉ b·∫°n t√πy ch·ªânh sau.
    # if st.session_state.is_processing:
    #     st.markdown(
    #         '<div class="bubble-row"><div class="typing"><span></span><span></span><span></span></div></div>',
    #         unsafe_allow_html=True
    #     )
    
# Suggested quick replies based on state
options_container = st.container()

with options_container:
    if st.session_state.chat_state == CHAT_STATE_TAM_SU_SELECTION:
        st.markdown("#### G·ª£i √Ω c·∫£m x√∫c")
        moods = list(CONFIG["tam_su"]["moods"].keys())
        cols = st.columns(len(moods))
        for i, mood in enumerate(moods):
            if cols[i].button(mood, key=f"mood_{i}"):
                st.session_state.chat_state = CHAT_STATE_TAM_SU_CHAT
                st.session_state.current_mood = mood
                st.session_state.turns = 0
                respond_bot(CONFIG["tam_su"]["moods"][mood]["initial"])
                st.rerun()

    elif st.session_state.chat_state == CHAT_STATE_TAM_SU_CHAT:
        st.markdown("#### T√πy ch·ªçn")
        col1, col2 = st.columns(2)
        if col1.button(CONFIG["tam_su"]["positive_affirmation_trigger"], use_container_width=True):
            affirm = random.choice(CONFIG["tam_su"]["positive_affirmations"])
            st.session_state.chat_state = CHAT_STATE_MAIN
            respond_bot(affirm)
            st.rerun()
        if col2.button("üèÅ K·∫øt th√∫c", use_container_width=True):
            st.session_state.chat_state = CHAT_STATE_MAIN
            respond_bot(random.choice(CONFIG["general"]["end_chat_replies"]))
            st.rerun()

    elif st.session_state.chat_state == CHAT_STATE_GIAO_TIEP_SELECTION_BASIC:
        st.markdown("#### T√¨nh hu·ªëng c∆° b·∫£n")
        # Th√™m n√∫t chuy·ªÉn sang T√¨nh hu·ªëng n√¢ng cao
        if st.button("Xem t√¨nh hu·ªëng n√¢ng cao ‚û°Ô∏è", key="btn_ext_scenarios"):
            st.session_state.chat_state = CHAT_STATE_GIAO_TIEP_SELECTION_EXTENDED
            st.rerun()

        for scenario in CONFIG["giao_tiep"]["scenarios_basic"].keys():
            if st.button(scenario, use_container_width=True, key=f"scenario_basic_{scenario}"):
                st.session_state.chat_state = CHAT_STATE_GIAO_TIEP_PRACTICE
                st.session_state.current_scenario = scenario
                respond_bot(CONFIG["giao_tiep"]["scenarios_basic"][scenario])
                st.rerun()

    elif st.session_state.chat_state == CHAT_STATE_GIAO_TIEP_SELECTION_EXTENDED:
        st.markdown("#### T√¨nh hu·ªëng n√¢ng cao")
        # Th√™m n√∫t quay l·∫°i T√¨nh hu·ªëng c∆° b·∫£n
        if st.button("‚¨ÖÔ∏è Quay l·∫°i t√¨nh hu·ªëng c∆° b·∫£n", key="btn_basic_scenarios"):
            st.session_state.chat_state = CHAT_STATE_GIAO_TIEP_SELECTION_BASIC
            st.rerun()
            
        for scenario in CONFIG["giao_tiep"]["scenarios_extended"].keys():
            if st.button(scenario, use_container_width=True, key=f"scenario_extended_{scenario}"):
                st.session_state.chat_state = CHAT_STATE_GIAO_TIEP_PRACTICE
                st.session_state.current_scenario = scenario
                respond_bot(CONFIG["giao_tiep"]["scenarios_extended"][scenario])
                st.rerun()

    elif st.session_state.chat_state == CHAT_STATE_GIAO_TIEP_PRACTICE:
        st.markdown("#### B·∫°n ƒë√£ hi·ªÉu ch∆∞a?")
        b1, b2, b3 = st.columns(3)
        if b1.button(CONFIG["giao_tiep"]["confirm_buttons"]["understood"], use_container_width=True):
            # Sau khi hi·ªÉu, chuy·ªÉn sang ch·∫ø ƒë·ªô m·ªü r·ªông
            st.session_state.chat_state = CHAT_STATE_GIAO_TIEP_SELECTION_EXTENDED
            respond_bot("Tuy·ªát v·ªùi! C√πng xem c√°c t√¨nh hu·ªëng m·ªü r·ªông nh√©!")
            st.rerun()
        if b2.button(CONFIG["giao_tiep"]["confirm_buttons"]["not_understood"], use_container_width=True):
            sc = st.session_state.current_scenario
            # L·∫•y l·∫°i text k·ªãch b·∫£n
            text = CONFIG["giao_tiep"]["scenarios_basic"].get(sc) or CONFIG["giao_tiep"]["scenarios_extended"].get(sc, "M√¨nh ch∆∞a r√µ k·ªãch b·∫£n n√†y.")
            respond_bot(f"Kh√¥ng sao c·∫£, m√¨nh n√≥i l·∫°i nh√©:\n\n{text}")
            st.rerun()
        if b3.button("‚èπÔ∏è D·ª´ng", use_container_width=True):
            st.session_state.chat_state = CHAT_STATE_MAIN
            respond_bot(random.choice(CONFIG["general"]["end_chat_replies"]))
            st.rerun()


# Chat input
# S·ª≠ d·ª•ng placeholder ƒë·ªÉ hi·ªÉn th·ªã Typing Indicator khi logic ƒëang ch·∫°y
user_text = st.chat_input(CONFIG["ui"]["input_placeholder"], disabled=st.session_state.is_processing)

if user_text and not st.session_state.is_processing:
    # B·∫ÆT ƒê·∫¶U X·ª¨ L√ù
    
    # 1. Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng
    add_message("user", user_text)
    st.session_state.turns += 1

    # 2. Hi·ªÉn th·ªã Typing Indicator T·∫†I ƒê√ÇY (tr∆∞·ªõc khi g·ªçi h√†m block)
    # Tuy nhi√™n, do Streamlit ho·∫°t ƒë·ªông, c√°ch t·ªët nh·∫•t l√† d√πng st.spinner()
    with message_container:
         # Th√™m placeholder cho hi·ªáu ·ª©ng ƒëang g√µ
         typing_placeholder = st.empty()
         typing_placeholder.markdown(
            '<div class="bubble-row"><div class="typing"><span></span><span></span><span></span></div></div>',
            unsafe_allow_html=True
         )
         
    # 3. L·∫•y ph·∫£n h·ªìi BOT
    if st.session_state.chat_state == CHAT_STATE_TAM_SU_CHAT:
        mood = st.session_state.current_mood
        styles_all = sum(CONFIG["tam_su"]["moods"][mood]["styles"].values(), [])
        response_text = random.choice(styles_all)
        if st.session_state.turns >= 2:
            st.session_state.chat_state = CHAT_STATE_AWAITING_FOLLOWUP
            final_response = f"{response_text} {CONFIG['general']['follow_up_prompt']}"
        else:
            final_response = response_text
        
        # M√¥ ph·ªèng th·ªùi gian ch·ªù
        time.sleep(random.uniform(0.5, 1.5))

    elif st.session_state.chat_state in (CHAT_STATE_MAIN, CHAT_STATE_AWAITING_FOLLOWUP):
        detected = detect_mood_from_text(user_text)
        if detected:
            st.session_state.
